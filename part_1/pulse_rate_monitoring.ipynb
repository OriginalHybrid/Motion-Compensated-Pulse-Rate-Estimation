{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Dataset\n",
    " **Troika** dataset is used to build the algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data.\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Code Description** - The code is used to test the performance of the algorithm on the training dataset. You can run the `Evaluate` function to start the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import glob\n",
    "import scipy.stats\n",
    "import scipy.signal\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data Description**\n",
    "    - The dataset consist of signals from accelerometer and PPG sensors. \n",
    "    - The accelerometer has three channels, each corresponding to a space axis x, y, and z. I use the magnitude of these three channels as a distance calculation. \n",
    "    - Both signals have noise but combining them would produce good results. \n",
    "    - The data is sampled at 125Hz from 12 different subjects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fls, ref_fls = LoadTroikaDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_fls), len(ref_fls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_signal = sp.io.loadmat(ref_fls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 74.33920705,  76.35746606,  77.14285714,  74.66814159,\n",
       "         72.58064516,  71.68458781,  72.89416847,  73.44940152,\n",
       "         75.33482143,  76.8442623 ,  79.5990566 ,  79.11392405,\n",
       "         74.50331126,  70.83825266,  69.58762887,  71.94244604,\n",
       "         77.31958763,  80.29978587,  82.87292818,  83.51893096,\n",
       "         84.65011287,  88.23529412,  90.95920617,  92.87925697,\n",
       "         94.73684211,  97.28773585,  99.66777409, 101.58013544,\n",
       "        102.84810127, 103.44827586, 103.17460317, 102.95670539,\n",
       "        103.28389831, 104.05549626, 106.20915033, 108.58324716,\n",
       "        110.66969353, 111.58342189, 112.29946524, 112.78195489,\n",
       "        113.63636364, 114.50381679, 115.13157895, 116.02209945,\n",
       "        117.05685619, 118.54583772, 120.19230769, 121.8851571 ,\n",
       "        123.96694215, 125.78616352, 128.06830309, 130.86150491,\n",
       "        133.18534961, 135.49415515, 137.19512195, 138.88888889,\n",
       "        140.57331863, 141.65792235, 142.70613108, 143.00847458,\n",
       "        143.31210191, 143.46439957, 143.76996805, 144.23076923,\n",
       "        144.81707317, 145.70552147, 146.90721649, 148.2830385 ,\n",
       "        149.84227129, 151.27388535, 152.40641711, 153.72168285,\n",
       "        154.72312704, 155.22875817, 155.44041451, 155.27950311,\n",
       "        154.95867769, 154.72312704, 154.55531453, 155.11892451,\n",
       "        155.11892451, 155.11892451, 154.95867769, 154.22077922,\n",
       "        153.88768898, 153.72168285, 152.89699571, 152.73311897,\n",
       "        152.12981744, 151.51515152, 151.51515152, 151.59574468,\n",
       "        151.91897655, 152.08110993, 151.91897655, 151.7571885 ,\n",
       "        151.59574468, 151.434644  , 151.7571885 , 151.59574468,\n",
       "        151.59574468, 151.434644  , 150.95338983, 150.95338983,\n",
       "        150.79365079, 150.3164557 , 150.15806112, 149.52780693,\n",
       "        149.21465969, 149.37106918, 149.52780693, 150.15806112,\n",
       "        151.27388535, 152.59409969, 154.00410678, 155.11892451,\n",
       "        156.42151482, 157.72870662, 158.56236786, 159.40488842,\n",
       "        160.55045872, 161.11707841, 161.70431211, 162.20391349,\n",
       "        162.33766234, 162.70661157, 162.86644951, 162.87487073,\n",
       "        162.86644951, 163.21243523, 163.72141372, 164.40501044,\n",
       "        164.92146597, 165.44117647, 165.61514196, 165.44117647,\n",
       "        164.92146597, 164.40501044, 163.8917794 , 163.04347826,\n",
       "        161.8705036 , 160.77170418, 159.06680806, 157.3976915 ,\n",
       "        156.41293014, 155.60165975, 154.95867769, 154.22077922]),\n",
       " 148)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# heartbeat reference data\n",
    "\"\"\"\n",
    "Variable 'BPM0', which gives the BPM value in every 8-second time window. Note that two successive time windows \n",
    "overlap by 6 seconds. Thus the first value in 'BPM0' gives the calcualted heart rate ground-truth in \n",
    "the first 8 seconds, while the second value in 'BPM0' gives the calculated heart rate ground-truth \n",
    "from the 3rd second to the 10th second. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "reference_signal['BPM0'].reshape(-1), len(reference_signal['BPM0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4. ,   6. ,   3. , ...,  86. , 104. , 118.5]),\n",
       " array([-0.0702, -0.0702, -0.0546, ...,  0.4134,  0.4134,  0.4134]),\n",
       " array([ 0.3432,  0.3588,  0.3666, ..., -0.2808, -0.273 , -0.273 ]),\n",
       " array([0.9594, 0.9438, 0.936 , ..., 0.7254, 0.7176, 0.7254]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The first row has the ppg value\n",
    "#The last three rows are simultaneous recordings of acceleration data (in x-, y-, and z-axis).\n",
    "ppg, accx, accy, accz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37937, 37937, 37937, 37937)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ppg), len(accx), len(accy), len(accz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Error Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "    print(\"The best 90% confidence estimates\", percentile90_confidence)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulse Rate Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Algorithm Description** \n",
    "    1. The algorithm works as follows:  \n",
    "        - Performs bandpass filtering on both signals.\n",
    "        - Create features that would be helpful for the algorithm\n",
    "        - Train a RandomForestRegression.\n",
    "        \n",
    "    2. The specific aspects of the physiology that it takes advantage of: \n",
    "        - I used PPG signals for measuring heart rate. \n",
    "        - The capillaries in the wrist are filled with blood when the ventricles contract.\n",
    "        - When there are few red blood cells in these capillaries, the light from the PPG sensor will be reflected in a large amount. \n",
    "        - When the blood cells are many, they absorb the light, so the optical detector will detect less light.\n",
    "        - Changes in the light detected by the optical detector, will produce an oscillating waveform which is the pulse rate.\n",
    "        \n",
    "    3. A description of the algorithm outputs: The algorithm outputs the estimated frequency (in BPM) along with its confidence score.\n",
    "    \n",
    "    4. Confidence on algorithm outputs: The confidence is calculated based on the magnitude of a small area that contains the estimated spectral frequency relative to the magnitude sum of the entire spectrum.\n",
    "    \n",
    "    5. Common failure modes: \n",
    "        - The algorithm may not perform well in other stages of changing heart rate due to arm and hand movements.\n",
    "        - The length of records in data files are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    \"\"\" Calculates mean absolute errors and confidences\n",
    "    \n",
    "    Args:\n",
    "        data_fl: (string) Path to the signal file\n",
    "        ref_fl: (string) Path to the reference signal file\n",
    "        \n",
    "    Returns:\n",
    "        (np.array) Mean absolute errors\n",
    "        (np.array) Confidences\n",
    "    \"\"\"\n",
    "    # Load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    \n",
    "    # load the reference signal\n",
    "    ground_truth = scipy.io.loadmat(ref_fl)['BPM0'].reshape(-1)\n",
    "    \n",
    "    errs = []\n",
    "    confs = []\n",
    "    \n",
    "    start_indices, end_indices = get_start_end(len(accx), len(ground_truth))\n",
    "    \n",
    "    for i, start in enumerate(start_indices):\n",
    "        end = end_indices[i]\n",
    "        ref = ground_truth[i]\n",
    "        \n",
    "        # Bandpass filtering the signals\n",
    "        w_ppg =  bandpass_filter(ppg[start:end])\n",
    "        w_accx = bandpass_filter(accx[start:end])\n",
    "        w_accy = bandpass_filter(accy[start:end])\n",
    "        w_accz = bandpass_filter(accz[start:end])\n",
    "        \n",
    "        # Get features\n",
    "        feature = Featurize(w_ppg, w_accx, w_accy, w_accz)\n",
    "        \n",
    "        # Get prediction\n",
    "        pred = model.predict(np.reshape(feature, (1, -1)))[0]\n",
    "        \n",
    "        # calculate confidence\n",
    "        n = len(w_ppg) * 4\n",
    "        freqs = np.fft.rfftfreq(n, 1/fs)\n",
    "        fft = np.abs(np.fft.rfft(w_ppg,n))\n",
    "        fft[freqs <= 40/60.0] = 0.0\n",
    "        fft[freqs >= 240/60.0] = 0.0\n",
    "    \n",
    "        est_fs = pred / 55.0\n",
    "        fs_win = 30  / 60.0\n",
    "        fs_win_e = (freqs >= est_fs - fs_win) & (freqs <= est_fs +fs_win)\n",
    "        conf = np.sum(fft[fs_win_e])/np.sum(fft)\n",
    "        \n",
    "        errs.append(np.abs(pred - ref))\n",
    "        confs.append(conf)\n",
    "    \n",
    "    errs = np.array(errs)\n",
    "    confs = np.array(confs)\n",
    "    # Return mean absolute error and confidence as a 2-tuple of numpy arrays.\n",
    "    return errs, confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 125\n",
    "window_shift = 2\n",
    "window_length = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end(sig_len, ref_len):\n",
    "    \"\"\" Returns the start and end indices of a signal \"\"\"\n",
    "    n = ref_len if ref_len < sig_len else sig_len\n",
    "    start = (np.cumsum(np.ones(n) * fs * window_shift) - fs * window_shift).astype(int) # windows shift of 2\n",
    "    return (start, start + window_length * fs) # windows length of 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(signal, band_pass = (40/60, 240/60), fs = fs):\n",
    "    \"\"\" Performs a bandpass filter on the signal. \"\"\"\n",
    "    \n",
    "    b,a = scipy.signal.butter(3, band_pass, fs=fs, btype= 'bandpass')\n",
    "    \n",
    "    # Perform forward and backward digital butterworth filter\n",
    "    return scipy.signal.filtfilt(b,a,signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Featurize(ppg, accx, accy, accz):\n",
    "    \"\"\" Create features \"\"\"\n",
    "\n",
    "    n = len(ppg) * 4\n",
    "    freqs = np.fft.rfftfreq(n, 1/fs)\n",
    "    fft = np.abs(np.fft.rfft(ppg,n))\n",
    "    fft[freqs <= 40/60.0] = 0.0\n",
    "    fft[freqs >= 240/60.0] = 0.0\n",
    "    \n",
    "    acc_mag = np.sqrt(accx**2 + accy**2 + accz**2)\n",
    "    acc_fft = np.abs(np.fft.rfft(acc_mag, n))\n",
    "    acc_fft[freqs <= 40/60.0] = 0.0\n",
    "    acc_fft[freqs >= 240/60.0] = 0.0\n",
    "    \n",
    "    ppg_feature = freqs[np.argmax(fft)]\n",
    "    acc_feature = freqs[np.argmax(acc_fft)]\n",
    "    \n",
    "    return np.array([ppg_feature, acc_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    global model\n",
    "    \n",
    "    if model: return\n",
    "    \n",
    "    print(\"Starting...\")\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    \n",
    "    targets, features, subjects = [], [], []\n",
    "    \n",
    "    for data_fl, ref_fl in (zip(data_fls, ref_fls)):\n",
    "        \n",
    "        # Load data using LoadTroikaDataFile\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "\n",
    "        # load the reference signal\n",
    "        ground_truth = scipy.io.loadmat(ref_fl)['BPM0'].reshape(-1)\n",
    "\n",
    "        start_indices, end_indices = get_start_end(len(accx), len(ground_truth))\n",
    "        \n",
    "        subject_name = os.path.basename(data_fl).split('.')[0]  \n",
    "        for i, start in enumerate(start_indices):\n",
    "            end = end_indices[i]\n",
    "            \n",
    "            # Bandpass filtering the signals\n",
    "            w_ppg =  bandpass_filter(ppg[start:end])\n",
    "            w_accx = bandpass_filter(accx[start:end])\n",
    "            w_accy = bandpass_filter(accy[start:end])\n",
    "            w_accz = bandpass_filter(accz[start:end])\n",
    "\n",
    "            # Get features\n",
    "            feature = Featurize(w_ppg, w_accx, w_accy, w_accz)\n",
    "\n",
    "            targets.append(ground_truth[i])\n",
    "            features.append(feature)\n",
    "            subjects.append(subject_name)\n",
    "            \n",
    "    targets = np.array(targets)\n",
    "    features = np.array(features)\n",
    "    \n",
    "    # Start training\n",
    "    regression = RandomForestRegressor(n_estimators=220,max_depth=15)\n",
    "    lf = KFold(n_splits=8)\n",
    "    splits = lf.split(features,targets,subjects)\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(splits):\n",
    "        X_train, y_train = features[train_idx], targets[train_idx]\n",
    "        X_test, y_test = features[test_idx], targets[test_idx]\n",
    "        regression.fit(X_train, y_train)\n",
    "    \n",
    "    model = regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    train_model()\n",
    "    \n",
    "    print(\"Start evaluating...\")\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Start evaluating...\n",
      "The best 90% confidence estimates 0.3904913152188008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.81324105520044"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Algorithm Performance**\n",
    "    - The performance is calculated using the mean absolute error between the estimations and the ground truth signal.\n",
    "    - To limit the noise coming from hand and arm movements, I used the acceleration magnitude. Also, the accelerometer magnitude is close to 1 g, which means the total force on the accelerometer is only due to gravity. But if you look at the individual channels, they shift around.\n",
    "    - One can use other metrics like accuracy, recall, percision, f1-score.\n",
    "    - The mean absolute error of the algorithm when evaluated on the test set is 7.81.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
